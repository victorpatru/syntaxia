name: Convex Reviewer

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    paths:
      - 'packages/backend/convex/**'
      - '**/convex/**'

concurrency:
  group: convex-reviewer-${{ github.event.pull_request.number }}
  cancel-in-progress: true

permissions:
  pull-requests: write
  contents: read
  issues: write

jobs:
  convex-reviewer:
    runs-on: ubuntu-latest
    if: github.event.pull_request.draft == false
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Install Cursor CLI
        run: |
          curl https://cursor.com/install -fsS | bash
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH

      - name: System and PR stats
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "::group::System info"
          uname -a || true
          nproc --all || true
          free -h || true
          echo "::endgroup::"

          echo "::group::PR stats"
          DIFF_BYTES=$(gh pr diff ${{ github.event.pull_request.number }} | wc -c)
          CHANGED_CONVEX_FILES=$(gh pr diff ${{ github.event.pull_request.number }} | grep -E '^diff --git a/.*/convex/|^diff --git a/packages/backend/convex/' | wc -l)
          echo "diff_bytes=$DIFF_BYTES" | tee -a metrics.txt
          echo "changed_convex_files=$CHANGED_CONVEX_FILES" | tee -a metrics.txt
          echo "::endgroup::"

      - name: Configure git identity
        run: |
          git config user.name "Convex Best Practices Bot"
          git config user.email "convex-bot@syntaxia.com"

      - name: Check for existing Convex comments
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh api repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/comments \
            --jq '.[] | select(.body | contains("convex-rule")) | .body' > existing_comments.txt
          gh api repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/reviews \
            --jq '.[] | select(.body | contains("convex-rule")) | .body' >> existing_comments.txt
          gh api repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/reviews \
            --jq '.[] | select(.user.login == "github-actions[bot]") | .body' >> existing_comments.txt
          echo "Found $(wc -l < existing_comments.txt | tr -d ' ') existing comments"

      - name: Load Convex best practices
        run: |
          echo "Loading Convex best practices reference..."
          cat .github/convex-best-practices.md > convex_practices.md

      - name: Analyze Convex code for violations
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
          MODEL: auto
          PROMPT: |
            You are a Convex code analyzer. Analyze ONLY the changed Convex files for best practices violations.

            Context:
            - PR: ${{ github.event.pull_request.number }}
            - Repository: ${{ github.repository }}

            Reference the Convex best practices document in convex_practices.md for detailed examples and explanations.

            Your task:
            1. Read convex_practices.md to understand all 15 violation types
            2. Get the PR diff: gh pr diff ${{ github.event.pull_request.number }}
            3. Focus ONLY on files in packages/backend/convex/ or any path containing 'convex/'
            4. Analyze changed lines against the 15 violations from the reference document

            ANALYSIS PROCESS:
            - Show your step-by-step analysis for each file
            - Explain WHY each violation exists and WHY it matters (reference the best practices doc)
            - Include line-by-line reasoning for violations found
            - Mention checks that passed (no violation found)
            - For missing await detection: Look at 2-3 lines before ctx.* calls to find 'await' or 'const x = await'
            - Be extra careful with multi-line statements - 'await' may be on a previous line
            - Use the examples from convex_practices.md to guide your analysis
            - De-duplicate repeats of the same rule within the same file/function by emitting a single VIOLATION with the earliest line_number; append the other line numbers in parentheses at the end of fix_suggestion like "(also at lines: 123, 456)"

            Output format:

            ANALYSIS_START
            [Explain your analysis process, what you checked, reasoning for each violation]
            ANALYSIS_END

            For each violation found, output EXACTLY this format:
            VIOLATION|[rule_number]|[file_path]|[line_number]|[category]|[description]|[fix_suggestion]

            Example:
            ANALYSIS_START
            Checking schema.ts lines 110-120: Found by_user index on line 115. Also found by_user_status composite index on line 117. Since composite indexes can handle queries on prefix fields, the by_user index is redundant and wastes storage.

            Checking sessions.ts lines 300-305: Found 'const sessionId = await ctx.runMutation(...)' on line 303. The 'await' keyword is present before ctx.runMutation, so this is correctly awaited. NO VIOLATION.
            ANALYSIS_END
            VIOLATION|8|packages/backend/convex/schema.ts|115|Performance|Redundant index - by_user covered by by_user_status|Remove the by_user index

            If no violations found, output:
            ANALYSIS_START
            [Explain what you checked and why no violations were found]
            ANALYSIS_END
            NO_VIOLATIONS_FOUND

            IMPORTANT: Only analyze changed lines, provide specific line numbers, include detailed reasoning.
        run: |
          echo "::group::Analyze (cursor-agent)"
          ANALYZE_START=$(date +%s%3N)
          /usr/bin/time -v cursor-agent --force --model "$MODEL" --output-format=text --print "$PROMPT" > analysis_output.txt 2> cursor_time.txt
          ANALYZE_END=$(date +%s%3N)
          ANALYZE_MS=$((ANALYZE_END - ANALYZE_START))
          RAW=$(grep -c '^VIOLATION|' analysis_output.txt || true)
          echo "analyze_ms=$ANALYZE_MS" | tee -a metrics.txt
          echo "violations_raw=$RAW" | tee -a metrics.txt
          echo "::endgroup::"

      - name: Deduplicate analysis output
        run: |
          # Collapse duplicate findings across identical rule/file/category/description/fix; keep earliest line
          DEDUP_START=$(date +%s%3N)
          awk -F'|' '
          $1=="VIOLATION"{
            key=$2 "|" $3 "|" $5 "|" $6 "|" $7
            if (!(key in min) || $4 < min[key]) min[key]=$4
            if (key in lines) { lines[key]=lines[key] "," $4 } else { lines[key]=$4 }
            rule[key]=$2; path[key]=$3; cat[key]=$5; desc[key]=$6; fix[key]=$7
          }
          END{
            for (k in min) {
              extra = (lines[k] ~ /,/) ? " (also at lines: " lines[k] ")" : ""
              printf "VIOLATION|%s|%s|%s|%s|%s|%s%s\n", rule[k], path[k], min[k], cat[k], desc[k], fix[k], extra
            }
          }' analysis_output.txt > analysis_dedup.txt
          DEDUP_END=$(date +%s%3N)
          DEDUP_MS=$((DEDUP_END - DEDUP_START))
          RAW=$(grep -c '^VIOLATION|' analysis_output.txt || true)
          DEDUP=$(grep -c '^VIOLATION|' analysis_dedup.txt || true)
          SAVED=$((RAW - DEDUP))
          echo "dedup_ms=$DEDUP_MS" | tee -a metrics.txt
          echo "violations_dedup=$DEDUP" | tee -a metrics.txt
          echo "violations_saved=$SAVED" | tee -a metrics.txt
          echo "Deduplicated violations: $DEDUP (saved $SAVED from $RAW)"

      - name: Show analysis results
        run: |
          echo "=== CURSOR-AGENT ANALYSIS OUTPUT ==="
          # Showing deduplicated output for clarity
          cat analysis_dedup.txt
          echo "=== END ANALYSIS OUTPUT ==="

      - name: Create GitHub review from analysis
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Still honor NO_VIOLATIONS_FOUND from the raw analyzer output
          if grep -q "NO_VIOLATIONS_FOUND" analysis_output.txt; then
            echo "No violations found, skipping review creation"
            exit 0
          fi

          # Count violations after deduplication
          violation_count=$(grep -c "VIOLATION|" analysis_dedup.txt || echo "0")
          
          if [ "$violation_count" -eq 0 ]; then
            echo "No violations found, skipping review creation"
            exit 0
          fi

          if [ "$violation_count" -eq 1 ]; then
            summary="Found 1 Convex best practice improvement."
          else
            summary="Found $violation_count Convex best practice improvements."
          fi

          # Start building the review JSON
          cat > review.json << EOF
          {
            "event": "COMMENT",
            "body": "$summary",
            "comments": [
          EOF

          # Process each violation and add to comments array
          first=true
          while IFS='|' read -r prefix rule_num file_path line_num category description fix; do
            if [ "$prefix" = "VIOLATION" ]; then
              # Stable dedupe key across pushes: rule + full path + category + hash(description)
              # Note: Excluding 'fix' avoids churn when line lists change (e.g., "also at lines: ...")
              hash=$(printf "%s" "$description" | sha1sum | awk '{print $1}')
              comment_id="convex-rule-${rule_num}-${file_path}-${category}-${hash}"
              if grep -q "$comment_id" existing_comments.txt; then
                echo "Skipping duplicate comment: $comment_id"
                continue
              fi

              # Determine emoji based on category
              case "$category" in
                "Critical") emoji="ðŸš¨" ;;
                "Performance") emoji="âš¡" ;;
                "Quality") emoji="âš ï¸" ;;
                *) emoji="â„¹ï¸" ;;
              esac

              # Add comma if not first comment
              if [ "$first" = false ]; then
                echo "," >> review.json
              fi
              first=false

              # Escape strings safely for JSON
              body_raw="$emoji $category: $description\n\n<!-- $comment_id -->\n\n**Fix:** $fix"
              body_json=$(printf "%s" "$body_raw" | jq -Rs .)
              path_json=$(printf "%s" "$file_path" | jq -Rs .)

              # Add the comment to JSON
              cat >> review.json << EOF
              {
                "path": $path_json,
                "line": $line_num,
                "side": "RIGHT",
                "body": $body_json
              }
          EOF
            fi
          done < analysis_dedup.txt

          # Close the JSON
          cat >> review.json << EOF
            ]
          }
          EOF

          if [ "$first" = true ]; then
            echo "No new violations to report"
            exit 0
          fi

          echo "Submitting review with $(jq '.comments | length' review.json) comments"
          gh api repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/reviews \
            -X POST --input review.json

      - name: Upload reviewer artifacts
        uses: actions/upload-artifact@v4
        with:
          name: convex-reviewer-logs-${{ github.event.pull_request.number }}
          path: |
            analysis_output.txt
            analysis_dedup.txt
            cursor_time.txt
            review.json
            metrics.txt

      - name: Append performance summary
        run: |
          echo "### Convex Reviewer Metrics" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          {
            echo "| Metric | Value |"
            echo "|---|---|"
            grep -E '^(analyze_ms|dedup_ms|violations_raw|violations_dedup|violations_saved|diff_bytes|changed_convex_files)=' metrics.txt | while IFS='=' read -r k v; do
              echo "| $k | $v |"
            done
          } >> $GITHUB_STEP_SUMMARY